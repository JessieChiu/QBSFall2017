{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Model Building\"\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Load Packages\n\nLoad all required packages.\n\n```{r library, include=FALSE}\nlibrary(readr)\nlibrary(rstan)\nlibrary(rethinking)\n```\n\n## Building Model 1\n\n### Import Data\n\nImport the Model 1 Dataset.\n\n```{r import.m1}\n# read files\ndata1 = read.csv(file.path(\"datasets\", \"M1.data.new.csv\"))\n```\n\n### Preprocess Data\n\nStep 1 :  Preprocess all variables to its correct numeric values.\n\nStep 2 :  Make log version of outcome to examine the magnitude of such.\n\nStep 3 :  Center predictors for better inference.\n\nStep 4 :  Also, for better efficiency and to avoid common problems later on in Stan, we make a new trimmed down data frame.\n\n```{r pre.m1, eval=FALSE}\n# factor to numeric\ndata1$crime_cases = as.numeric(as.character(data1$Total_cases_Number))\n# fix NAs\ndata1[1,\"crime_cases\"] = 115879\n\n# make log version of outcome\ndata1$log_crime = log(data1$crime_cases)\n\n# construct centered predictor \ndata1$Bx1_c<- data1$Bx1 - mean(data1$Bx1)\ndata1$Bx2_c<- data1$Bx2 - mean(data1$Bx2)\ndata1$Bx3_c<- data1$Bx3 - mean(data1$Bx3)\n\n# trim data frame\nd1 = data1[ , c(\"log_crime\",\"Bx1_c\",\"Bx2_c\",\"Bx3_c\")]\n```\n\n```{r pre.m1.2, include=FALSE}\n# factor to numeric\ndata1$crime_cases = as.numeric(as.character(data1$Total_cases_Number))\n# fix NAs\ndata1[1,\"crime_cases\"] = 115879\n\n# make log version of outcome\ndata1$log_crime = log(data1$crime_cases)\n\n# construct centered predictor \ndata1$Bx1_c<- data1$Bx1 - mean(data1$Bx1)\ndata1$Bx2_c<- data1$Bx2 - mean(data1$Bx2)\ndata1$Bx3_c<- data1$Bx3 - mean(data1$Bx3)\n\n# trim data frame\nd1 = data1[ , c(\"log_crime\",\"Bx1_c\",\"Bx2_c\",\"Bx3_c\")]\n```\n\n### Build Model\n\nFit the model using quadratic approximation (map).\n\n```{r m1}\n# define model fit by map\nm1 <- map(\n  alist(\n    log_crime ~ dnorm(mu, sigma),\n    mu <- a +b1*Bx1_c + b2*Bx2_c + b3*Bx3_c,\n    a ~ dnorm(11,100),\n    b1 ~ dnorm(0,1),\n    b2 ~ dnorm(0,1),\n    b3 ~ dnorm(0,1),\n    sigma ~ dunif(0,10)\n  ),\n  data <- d1)\n```\n\nFit the model using Hamiltonian Monte Carlo (map2stan).\n```{r m1.stan, eval=FALSE}\n# define model fit by map2stan\nm1.stan <- map2stan(\n    alist(\n    log_crime ~ dnorm(mu, sigma),\n    mu <- a +b1*Bx1_c + b2*Bx2_c + b3*Bx3_c,\n    a ~ dnorm(11,100),\n    b1 ~ dnorm(0,1),\n    b2 ~ dnorm(0,1),\n    b3 ~ dnorm(0,1),\n    sigma ~ dcauchy(0,2)\n  ),\n  data <- d1)\n```\n\n```{r m1.stan.2, include=FALSE}\n# define model fit by map2stan\nm1.stan <- map2stan(\n    alist(\n    log_crime ~ dnorm(mu, sigma),\n    mu <- a +b1*Bx1_c + b2*Bx2_c + b3*Bx3_c,\n    a ~ dnorm(11,100),\n    b1 ~ dnorm(0,1),\n    b2 ~ dnorm(0,1),\n    b3 ~ dnorm(0,1),\n    sigma ~ dcauchy(0,2)\n  ),\n  data <- d1)\n```\n\n### Parameter Overview\n\nCompare map to map2stan to check the quadratic approximation. From the table of coefficients, we can see that the numbers are approximately the same.\n\n```{r m1.coeftab}\ncoeftab(m1, m1.stan)\n```\n\nFor the Stan model and these data, the resulting posterior distribution is quite nearly multivariate Gaussian. The density for sigma is certainly skewed in a certain direction, but otherwise the quadratic approximation does almost as well as Hamiltonian Monte Carlo. Since the quadratic approximation turned out to be okay, we can continue to use map estimates.\n\nHowever, there remain strong correlations between multiple parameters (b1, b2, and b3, specifically) even though we centered the predictors prior to fitting. This needs to be taken into consideration when examining the model.\n\n```{r m1.stan.pairs}\npairs(m1.stan)\n```\n\n## Building Model 2\n\n### Import Data\n\nImport the Model 2 Dataset.\n\n```{r import.m2}\n# read files\ndata2 = read.csv(file.path(\"datasets\", \"M2.data.new.csv\"))\n```\n\n### Preprocess Data\n\nStep 1 : Preprocess all variables to its correct numeric values.\n\nStep 2 : Make log version of outcome to examine the magnitude of such.\n\nStep 3 : For better efficiency and to avoid common problems later on in Stan, we make a new trimmed down data frame.\n\n```{r pre.m2, eval=FALSE}\n# factor to numeric\ndata2$crime_cases = as.numeric(as.character(data2$Total_cases_Number))\n# fix NAs\ndata2[1,\"crime_cases\"] = 115879\n\n# make log version of outcome\ndata2$log_crime = log(data2$crime_cases)\n\n# trim data frame\nd2 = data2[ , c(\"log_crime\",\"log_box_office\",\"score.s\",\"Bscore.s\")]\n```\n\n```{r pre.m2.2, include=FALSE}\n# factor to numeric\ndata2$crime_cases = as.numeric(as.character(data2$Total_cases_Number))\n# fix NAs\ndata2[1,\"crime_cases\"] = 115879\n\n# make log version of outcome\ndata2$log_crime = log(data2$crime_cases)\n\n# trim data frame\nd2 = data2[ , c(\"log_crime\",\"log_box_office\",\"score.s\",\"Bscore.s\")]\n```\n\n### Build Model\n\nFit the model using quadratic approximation (map).\n\n```{r m2}\n# define model fit by map\nm2 <- map(\n  alist(\n    log_crime ~ dnorm(mu, sigma),\n    mu <- a +b1*log_box_office + b2*score.s + b3*Bscore.s,\n    a ~ dnorm(11,100),\n    b1 ~ dnorm(0,1),\n    b2 ~ dnorm(0,1),\n    b3 ~ dnorm(0,1),\n    sigma ~ dunif(0,10)\n  ),\n  data <- d2)\n```\n\nFit the model using Hamiltonian Monte Carlo (map2stan).\n\n```{r m2.stan, eval=FALSE}\n# define model fit by map2stan\nm2.stan <- map2stan(\n    alist(\n    log_crime ~ dnorm(mu, sigma),\n    mu <- a +b1*log_box_office + b2*score.s + b3*Bscore.s,\n    a ~ dnorm(11,100),\n    b1 ~ dnorm(0,1),\n    b2 ~ dnorm(0,1),\n    b3 ~ dnorm(0,1),\n    sigma ~ dcauchy(0,2)\n  ),\n  data <- d2)\n```\n\n```{r m2.stan.2, include=FALSE}\n# define model fit by map2stan\nm2.stan <- map2stan(\n    alist(\n    log_crime ~ dnorm(mu, sigma),\n    mu <- a +b1*log_box_office + b2*score.s + b3*Bscore.s,\n    a ~ dnorm(11,100),\n    b1 ~ dnorm(0,1),\n    b2 ~ dnorm(0,1),\n    b3 ~ dnorm(0,1),\n    sigma ~ dcauchy(0,2)\n  ),\n  data <- d2)\n```\n\n### Parameter Overview\n\nCompare map to map2stan to check the quadratic approximation. From the table of coefficients, we can see that the numbers are approximately the same.\n\n```{r m2.coeftab}\ncoeftab(m2, m2.stan)\n```\n\nFor the Stan model and these data, the resulting posterior distribution is quite nearly multivariate Gaussian. The density for sigma is quite skewed in a certain direction, but otherwise the quadratic approximation does almost as well as Hamiltonian Monte Carlo. Since the quadratic approximation turned out to be okay, we can continue to use map estimates.\n\nHowever, there remain strong correlations between multiple parameters (a and b1, b2 and b3, specifically) even though we standardized the predictors prior to fitting. This needs to be taken into consideration when examining the model.\n\n```{r m2.stan.pairs}\npairs(m2.stan)\n```\n",
    "created" : 1513065746811.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "473306645",
    "id" : "28956815",
    "lastKnownWriteTime" : 1513306976,
    "last_content_update" : 1513306976991,
    "path" : "C:/Users/jestw/Desktop/QBS/QBS Group 2_final/Website/model.Rmd",
    "project_path" : "model.Rmd",
    "properties" : {
        "last_setup_crc32" : "AF4A5568bb338d19",
        "tempName" : "Untitled1"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}