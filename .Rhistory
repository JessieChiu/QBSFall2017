setwd("C:/Users/jestw/Desktop/QBS/QBS Group 2_final")
setwd("C:/Users/jestw/Desktop/QBS/QBS Group 2_final")
M1 = read.csv("M1.data.new.csv")
Q1 = read.csv("QBS-Q1-data-new.csv")
Q2 = read.csv("QBS-Q2-data-new.csv")
Q3 = read.csv("QBS-Q3-data-new.csv")
Q4 = read.csv("QBS-Q4-data-new.csv")
Y = read.csv("Crime-Rate.csv")
data = rbind(Q1,Q2,Q3,Q4)
# convert factor to numeric
data$box_office = as.numeric(data$box_office)
data$rotten_tomatoes = as.numeric(data$rotten_tomatoes)
data$Imbd = as.numeric(data$Imbd)
# convert box office to log for better comparison
data$log_box_office = log(data$box_office)
# compute mean score and overwrite NA values
A = (data$rotten_tomatoes + data$Imbd)/2
B = data$Imbd
data$score = ifelse(!is.na(data$rotten_tomatoes), A, B)
data = data[complete.cases(data[ , 8:9]), ]
data$score.s = (data$score - mean(data$score))/sd(data$score)
# text mining
require("xml2")
library('rvest')
library('NLP')
library('tm')
library('stringr')
category <- data$category
corpus <- Corpus(VectorSource(category))
## Data-Preprocessing: removing punctuation
corpus2 <- tm_map(corpus, removePunctuation)
## Data-Preprocessing: changing all to lower case
corpus2 <- tm_map(corpus2, tolower)
## Data-Preprocessing: removing whitespaces
corpus2 <- tm_map(corpus2, stripWhitespace)
corpus2 = sapply(corpus2, as.character)
data$category =as.factor(corpus2)
# determine x1=number of crime-inducing films------------------------------------------------
x1 = c("crime","thriller","horror","mystery","suspense")
x1 = paste(x1, collapse='|')
#####
x1_row = which(apply(data.frame(data$category), 1, function(i) str_detect(paste(i, collapse=','), x1)))
for(i in 1:481){
if (i %in% x1_row){
data[i,"x1"] = 1
} else{
data[i,"x1"] = 0
}
}
# determine x2=number of crime-reducing films------------------------------------------------
#install.packages("stringr")
x2 = c("family","kids","comedy","animation")
x2 = paste(x2, collapse='|')
x2_row = which(apply(data.frame(data$category), 1, function(i) str_detect(paste(i, collapse=','), x2)))
for(i in 1:481){
if (i %in% x2_row){
data[i,"x2"] = 1
} else{
data[i,"x2"] = 0
}
}
# determine x3=number of neutral films------------------------------------------------
data$x3 = ifelse(data$x1 +data$x2 == 0, 1, 0)
library(dplyr)
# Model 1:
extract.data = data %>%
group_by(year, Quarter) %>%
summarise(Bx1=mean(log_box_office*x1), Bx2=mean(log_box_office*x2), Bx3=mean(log_box_office*x3)) %>%
select(year, Quarter, Bx1, Bx2, Bx3)
extract.data = merge(Y, extract.data, by=c("year","Quarter"))
write.csv(extract.data, "M1.data.new.csv")
# Model 2:
extract.data = data %>%
group_by(year, Quarter) %>%
summarise(log_box_office=mean(log_box_office), score.s = mean(score.s), Bscore.s=mean(log_box_office*score.s)) %>%
select(year, Quarter, log_box_office, score.s, Bscore.s)
extract.data = merge(Y, extract.data, by=c("year","Quarter"))
write.csv(extract.data, "M2.data.new.csv")
M1 = read.csv("M1.data.new.csv")
M2 = read.csv("M2.data.new.csv")
complete.data = rbind(M1,M2)
View(M1)
View(M2)
View(M1)
View(M2)
?cbind
complete.data = cbind(M1,M2)
View(complete.data)
View(complete.data)
complete.data = rbind(M1,M2)
library(dplyr)
complete.data = bind_rows(M1,M2)
View(complete.data)
View(M1)
View(M1)
View(M2)
class(extract.data$Bscore.s)
extract.data = data %>%
group_by(year, Quarter) %>%
summarise(Bx1=mean(log_box_office*x1), Bx2=mean(log_box_office*x2), Bx3=mean(log_box_office*x3)) %>%
select(year, Quarter, Bx1, Bx2, Bx3)
extract.data = merge(Y, extract.data, by=c("year","Quarter"))
class(extract.data$Bx1)
library(plyr)
complete.data = rbind.fill(M1,M2)
View(complete.data)
?merge
complete.data = merge(M1,M2)
View(complete.data)
write.csv(complete.data, "Data.csv")
setwd("C:/Users/jestw/Desktop/CSX Data Science/L9")
install.packages("plot.nnet")
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
install.packages("plot.nnet")
library(devtools)
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
library(DMwR)
library(nnet)
library(reshape)
library(devtools)
library(scales)
library(ggplot2)
install.packages("DMwR")
library(DMwR)
library(nnet)
library(reshape)
install.packages("reshape")
library(reshape)
library(devtools)
library(scales)
library(ggplot2)
data(iris)
set.seed(1117)
#取得總筆數
n <- nrow(iris)
#設定訓練樣本數70%
t_size = round(0.7 * n)
#取出樣本數的idx
t_idx <- sample(seq_len(n), size = t_size)
#訓練組樣本
traindata <- iris[t_idx,]
#測試組樣本
testdata <- iris[ - t_idx,]
nnetM <- nnet(formula = Species ~ ., linout = T, size = 3, decay = 0.001, maxit = 1000, trace = T, data = traindata)
plot.nnet(nnetM, wts.only = F)
prediction <- predict(nnetM, testdata, type = 'class')
cm <- table(x = testdata$Species, y = prediction, dnn = c("實際", "預測"))
cm
nnetM <- nnet(formula = Species ~ ., linout = T, size = 6, decay = 0.001, maxit = 1000, trace = T, data = traindata)
plot.nnet(nnetM, wts.only = F)
install.packages("neuralnet")
library("neuralnet")
data <- iris
data$setosa <- ifelse(data$Species == "setosa", 1, 0)
data$versicolor <- ifelse(data$Species == "versicolor", 1, 0)
data$virginica <- ifelse(data$Species == "virginica", 1, 0)
f1 <- as.formula('setosa + versicolor + virginica  ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width')
bpn <- neuralnet(formula = f1, data = data, hidden = c(2,4),learningrate = 0.01)
print(bpn)
plot(bpn)
bpn <- neuralnet(formula = f1, data = data, hidden = c(3,5),learningrate = 0.01)
plot(bpn)
plot(bpn)
bpn <- neuralnet(formula = f1, data = data, hidden = c(2,3,5),learningrate = 0.01)
plot(bpn)
bpn <- neuralnet(formula = f1, data = data, hidden = c(2,4,3),learningrate = 0.01)
plot(bpn)
bpn <- neuralnet(formula = f1, data = data, hidden = c(3,4,3),learningrate = 0.01)
?neuralnet
library(caret)
model <- train(form = f1, data = traindata, method = "neuralnet",
tuneGrid = expand.grid(.layer1 = c(1:4), .layer2 = c(1:4), .layer3 = c(0)), learningrate = 0.01)
library(caret)
model <- train(form = f1, data = traindata, method = "neuralnet",
tuneGrid = expand.grid(.layer1 = c(1:4), .layer2 = c(1:4), .layer3 = c(0)), learningrate = 0.01)
model <- train(form = f1, data = traindata, method = "neuralnet",
tuneGrid = expand.grid(.layer1 = c(1:4), .layer2 = c(1:4), .layer3 = c(2:3)), learningrate = 0.01)
View(traindata)
View(testdata)
View(data)
model <- train(form = f1, data = data, method = "neuralnet",
tuneGrid = expand.grid(.layer1 = c(1:4), .layer2 = c(1:4), .layer3 = c(0)), learningrate = 0.01)
